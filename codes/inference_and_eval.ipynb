{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2e867b-5c72-41d2-acfd-00e2a807183c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e93449b092b4c69a073084602ed27bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/338 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Loaded fine-tuned model (base + LoRA adapter).\n",
      "\n",
      "======================\n",
      "Fine-tuned model samples\n",
      "======================\n",
      "\n",
      "QTYPE: general\n",
      "Q: What is hypertension?\n",
      "A: Hypertension, also called high blood pressure, is a common condition in which the long-term force of the blood against your artery walls is higher than normal. Over time, high blood pressure can damage the walls of your arteries and make it harder for your heart to pump blood. It's the most common cause of heart disease and stroke, which are leading causes of death in the United States.    Hypertension often has no signs or symptoms. Many people who have it don't know they have it. That's why it's important to get your blood pressure checked regularly by a health care provider.    The main risk factor for developing hypertension is having a family history of the condition. Other risk factors include being overweight or obese; drinking too much alcohol; not getting enough potassium, calcium, or magnesium in your diet; and having diabetes or chronic kidney disease.    Your doctor may recommend lifestyle changes, such as losing weight, eating a healthy diet, and exercising more, to help control your\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "QTYPE: symptoms\n",
      "Q: What are common symptoms of influenza (flu)?\n",
      "A: The most common symptoms of the flu include fever, cough, sore throat, runny or stuffy nose, muscle or body aches, headaches, and fatigue (tiredness). Some people also have vomiting and diarrhea. These symptoms usually start 1 to 4 days after exposure to the virus. The severity of the illness varies from person to person.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "QTYPE: treatment\n",
      "Q: How is type 2 diabetes commonly treated?\n",
      "A: Type 2 diabetes is usually treated with diet, exercise, and oral medications. In some cases, insulin injections may be needed.\n",
      "                \n",
      "Diet\n",
      "                \n",
      "A healthy diet can help control blood glucose levels in people with type 2 diabetes. The diet should include:\n",
      "                \n",
      "Fiber-rich foods. Fiber helps slow the absorption of carbohydrates into the bloodstream. Foods high in fiber include fruits, vegetables, whole grains, and legumes (beans, lentils, and peas).\n",
      "                \n",
      "Protein. Protein helps keep your body's organs working well. Good sources of protein include lean meats, poultry, fish, beans, nuts, and seeds.\n",
      "                \n",
      "Fat. Fat is important for your health. It provides energy and helps your body absorb certain vitamins. Good sources of fat include avocados, nuts, seeds, and olive oil.\n",
      "                \n",
      "Carbohydrates. Carbohydrates provide energy for your body. They also affect your blood glucose level. Good sources of carbohydrates include fruits, vegetables, breads, cereals\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "QTYPE: safety\n",
      "Q: I have severe chest pain and shortness of breath. What should I do?\n",
      "A: If you have chest pain or shortness of breath, call 911 right away. Chest pain or shortness of breath can be a sign of a heart attack or other serious condition. These symptoms may also be signs of a stroke. Call 911 if you think you are having a heart attack or stroke.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "QTYPE: out_of_domain\n",
      "Q: Write a Python function to sort a list.\n",
      "A: def sort_list(list):    return sorted(list)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "======================\n",
      "BASE vs FINE-TUNED\n",
      "======================\n",
      "Q: What causes migraine headaches, and what are common treatments?\n",
      "\n",
      "---- BASE (adapter OFF) ----\n",
      "Migraine headaches are complex neurological disorders that can be caused by a combination of genetic, environmental, and physiological factors. Here's an overview of the causes and common treatments:\n",
      "\n",
      "### Causes of Migraines:\n",
      "1. **Genetics**: A family history of migraines increases the risk of developing them.\n",
      "2. **Environmental Factors**: Exposure to certain triggers such as bright lights, loud noises, strong smells, or weather changes can trigger migraines.\n",
      "3. **Hormonal Changes**: Hormonal fluctuations, particularly in women, can affect the frequency and severity of migraines.\n",
      "4. **Stress**: Emotional stress, physical tension, and mental strain can lead to migraines.\n",
      "5. **Dehydration**: Not drinking enough water can cause migraines.\n",
      "6. **Sleep Disorders**: Disrupted sleep patterns, including lack of sleep or irregular sleep schedules, can trigger migraines.\n",
      "7. **Food Sensitivities**: Certain foods like aged cheeses, processed meats, chocolate, and alcohol can trigger migraines in some people.\n",
      "8. **Medications**: Some medications, especially blood pressure drugs\n",
      "\n",
      "---- FINE-TUNED (adapter ON) ----\n",
      "Migraines are caused by a complex interaction of genetic, environmental, and hormonal factors. The exact cause is unknown. Migraines may be triggered by certain foods or drinks, stress, lack of sleep, or changes in the weather. Some people have migraines only when they are pregnant or during menstruation. Other people have them at any time. Migraines can also be triggered by certain medications, such as birth control pills, antidepressants, and some blood pressure medicines.\n",
      "\n",
      "======================\n",
      "Quick Overfitting Check (ROUGE-L F1)\n",
      "======================\n",
      "Train sample (n=15) mean ROUGE-L F1: 0.292\n",
      "Eval  sample (n=15) mean ROUGE-L F1: 0.214\n",
      "Rule of thumb: if train >> eval by a big margin, that suggests overfitting.\n",
      "\n",
      "Worst 3 EVAL examples (lowest ROUGE-L):\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ROUGE-L F1: 0.066 | qtype: exams and tests\n",
      "Q: How to diagnose Alzheimer's Caregiving ?\n",
      "PRED: A health care provider will diagnose Alzheimer's disease based on the signs and symptoms of the disease and a physical exam. The health care provider may also order blood tests to rule out other conditions that cause similar symptoms. The health care provider will ask about your family history ...\n",
      "REF : Now that your family member or friend has received a diagnosis of Alzheimers disease, its important to learn as much as you can about the disease and how to care for someone who has it. You may also want to know the right way to share the news with family and friends. Learning About Alzheimers ...\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ROUGE-L F1: 0.122 | qtype: treatment\n",
      "Q: What are the treatments for Wernicke-Korsakoff Syndrome ?\n",
      "PRED: There is no cure for Wernicke-Korsakoff syndrome. Treatment focuses on restoring brain function and preventing further damage. The following medications may be used to treat the condition: - thiamine (vitamin B1) - vitamin B6 Thiamine is given by mouth or intravenously. Vitamin B6 is given by ...\n",
      "REF : Treatment involves replacement of thiamine and providing proper nutrition and hydration. In some cases, drug therapy is also recommended.Stopping alcohol use may prevent further nerve and brain damage. In individuals with Wernicke's encephalopathy, it is very important to start thiamine ...\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ROUGE-L F1: 0.137 | qtype: information\n",
      "Q: Do you have information about Native Hawaiian and Pacific Islander Health\n",
      "PRED: Summary : The health of Native Hawaiians and other Pacific Islanders is important to the United States. They make up 1.3 percent of the U.S. population. Many Native Hawaiians and Pacific Islanders live in Hawaii. They also live in Alaska, California, Guam, Hawaii, Idaho, Illinois, Iowa, Kansas, ...\n",
      "REF : Summary : Every racial or ethnic group has specific health concerns. Differences in the health of groups can result from: - Genetics - Environmental factors - Access to care - Cultural factors On this page, you'll find links to health issues that affect Native Hawaiians and Pacific Islanders.\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 0) CONFIG (edit if needed)\n",
    "# =========================\n",
    "import os, math, random, textwrap\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "\n",
    "# Base model and where you saved the LoRA adapter\n",
    "BASE_MODEL_NAME = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "ADAPTER_DIR = r\".\\qwen25_1p5b_medqa_lora_cpu\\adapter\"   # <- from your logs\n",
    "DATA_PATH = r\"YOUR DIRECTORY to the Dataset\\Medical_QA_Dataset.csv\"\n",
    "\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are a careful medical information assistant. Provide general educational information, \"\n",
    "    \"not personal medical advice. Encourage consulting qualified clinicians for diagnosis and treatment. \"\n",
    "    \"If symptoms suggest an emergency, advise seeking urgent care. If unsure, say you don't know.\"\n",
    ")\n",
    "\n",
    "# CPU performance: use all cores (optional)\n",
    "try:\n",
    "    torch.set_num_threads(os.cpu_count() or 8)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Reproducibility for generation (optional)\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 1) LOAD Tokenizer + Model\n",
    "# =========================\n",
    "def load_model_cpu(model_name: str):\n",
    "    \"\"\"\n",
    "    Transformers v5+ may prefer dtype=... vs torch_dtype=...\n",
    "    We'll try dtype first, then fall back.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return AutoModelForCausalLM.from_pretrained(model_name, dtype=torch.float32, trust_remote_code=False)\n",
    "    except Exception:\n",
    "        return AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float32, trust_remote_code=False)\n",
    "\n",
    "# Load tokenizer from adapter folder (so it matches what you saved)\n",
    "tokenizer = AutoTokenizer.from_pretrained(ADAPTER_DIR, trust_remote_code=False)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "# Load base model + attach adapter\n",
    "base_model = load_model_cpu(BASE_MODEL_NAME)\n",
    "model_ft = PeftModel.from_pretrained(base_model, ADAPTER_DIR)\n",
    "model_ft.eval()\n",
    "\n",
    "print(\"[OK] Loaded fine-tuned model (base + LoRA adapter).\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 2) PROMPT + GENERATION\n",
    "# =========================\n",
    "def build_user_content(question: str, qtype: str | None = None) -> str:\n",
    "    if qtype and str(qtype).strip() and str(qtype).lower() not in {\"nan\", \"none\"}:\n",
    "        return f\"Question type: {qtype}\\n\\nQuestion: {question}\"\n",
    "    return question\n",
    "\n",
    "def build_chat_text(question: str, qtype: str | None = None) -> str:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": build_user_content(question, qtype=qtype)},\n",
    "    ]\n",
    "    # IMPORTANT: same pattern as training (add_generation_prompt=True)\n",
    "    return tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "@torch.inference_mode()\n",
    "def generate_answer(\n",
    "    model,\n",
    "    question: str,\n",
    "    qtype: str | None = None,\n",
    "    max_new_tokens: int = 256,\n",
    "    do_sample: bool = False,      # False = deterministic (greedy)\n",
    "    temperature: float = 0.7,     # used only if do_sample=True\n",
    "    top_p: float = 0.9,           # used only if do_sample=True\n",
    "    repetition_penalty: float = 1.05,\n",
    ") -> str:\n",
    "    text = build_chat_text(question, qtype=qtype)\n",
    "    inputs = tokenizer([text], return_tensors=\"pt\")\n",
    "    # CPU inference\n",
    "    inputs = {k: v.to(\"cpu\") for k, v in inputs.items()}\n",
    "\n",
    "    gen_kwargs = dict(\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=do_sample,\n",
    "        repetition_penalty=repetition_penalty,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "    if do_sample:\n",
    "        gen_kwargs.update(dict(temperature=temperature, top_p=top_p))\n",
    "\n",
    "    out = model.generate(**inputs, **gen_kwargs)\n",
    "\n",
    "    # decode only newly generated tokens\n",
    "    new_tokens = out[0][inputs[\"input_ids\"].shape[1]:]\n",
    "    return tokenizer.decode(new_tokens, skip_special_tokens=True).strip()\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 3) QUICK MANUAL TESTS (YOUR MODEL ONLY)\n",
    "# ============================================\n",
    "test_questions = [\n",
    "    (\"general\", \"What is hypertension?\"),\n",
    "    (\"symptoms\", \"What are common symptoms of influenza (flu)?\"),\n",
    "    (\"treatment\", \"How is type 2 diabetes commonly treated?\"),\n",
    "    (\"safety\", \"I have severe chest pain and shortness of breath. What should I do?\"),\n",
    "    (\"out_of_domain\", \"Write a Python function to sort a list.\"),  # should still respond, but may be less good\n",
    "]\n",
    "\n",
    "print(\"\\n======================\")\n",
    "print(\"Fine-tuned model samples\")\n",
    "print(\"======================\")\n",
    "for qt, q in test_questions:\n",
    "    ans = generate_answer(model_ft, q, qtype=qt, max_new_tokens=200, do_sample=False)\n",
    "    print(f\"\\nQTYPE: {qt}\\nQ: {q}\\nA: {ans}\\n{'-'*80}\")\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# 4) BASE vs FINE-TUNED COMPARISON (NO EXTRA MEMORY)\n",
    "#    We try to disable adapter temporarily for \"base\" output.\n",
    "# ==========================================================\n",
    "def can_disable_adapter(m) -> bool:\n",
    "    return hasattr(m, \"disable_adapter\")\n",
    "\n",
    "@torch.inference_mode()\n",
    "def compare_base_vs_ft(\n",
    "    question: str,\n",
    "    qtype: str | None = None,\n",
    "    max_new_tokens: int = 220,\n",
    "):\n",
    "    ft = generate_answer(model_ft, question, qtype=qtype, max_new_tokens=max_new_tokens, do_sample=False)\n",
    "\n",
    "    base = None\n",
    "    if can_disable_adapter(model_ft):\n",
    "        try:\n",
    "            with model_ft.disable_adapter():\n",
    "                base = generate_answer(model_ft, question, qtype=qtype, max_new_tokens=max_new_tokens, do_sample=False)\n",
    "        except Exception as e:\n",
    "            base = f\"[Could not disable adapter in this PEFT version: {e}]\"\n",
    "    else:\n",
    "        base = \"[This PEFT version does not support disable_adapter() easily.]\"\n",
    "\n",
    "    print(\"\\n======================\")\n",
    "    print(\"BASE vs FINE-TUNED\")\n",
    "    print(\"======================\")\n",
    "    print(f\"Q: {question}\\n\")\n",
    "    print(\"---- BASE (adapter OFF) ----\")\n",
    "    print(base)\n",
    "    print(\"\\n---- FINE-TUNED (adapter ON) ----\")\n",
    "    print(ft)\n",
    "\n",
    "# Example comparison\n",
    "compare_base_vs_ft(\"What causes migraine headaches, and what are common treatments?\", qtype=\"treatment\")\n",
    "\n",
    "\n",
    "# ==========================================================\n",
    "# 5) QUICK OVERFITTING SANITY CHECK (Train vs Eval ROUGE-L)\n",
    "#    - small sample size (CPU-friendly)\n",
    "#    - ROUGE-L is not perfect, but helps detect big train>eval gap\n",
    "# ==========================================================\n",
    "def rouge_l_f1(pred: str, ref: str) -> float:\n",
    "    # Simple whitespace tokenization\n",
    "    a = pred.lower().split()\n",
    "    b = ref.lower().split()\n",
    "    if not a or not b:\n",
    "        return 0.0\n",
    "\n",
    "    # LCS DP (O(n*m)) - OK for small lengths\n",
    "    n, m = len(a), len(b)\n",
    "    dp = [[0]*(m+1) for _ in range(n+1)]\n",
    "    for i in range(n):\n",
    "        ai = a[i]\n",
    "        for j in range(m):\n",
    "            if ai == b[j]:\n",
    "                dp[i+1][j+1] = dp[i][j] + 1\n",
    "            else:\n",
    "                dp[i+1][j+1] = max(dp[i][j+1], dp[i+1][j])\n",
    "    lcs = dp[n][m]\n",
    "    prec = lcs / max(n, 1)\n",
    "    rec  = lcs / max(m, 1)\n",
    "    if prec + rec == 0:\n",
    "        return 0.0\n",
    "    return (2 * prec * rec) / (prec + rec)\n",
    "\n",
    "def load_split_dataset(data_path: str, test_size: float = 0.05, seed: int = 42) -> tuple[Dataset, Dataset]:\n",
    "    df = pd.read_csv(data_path)[[\"qtype\", \"Question\", \"Answer\"]].copy()\n",
    "    df[\"qtype\"] = df[\"qtype\"].fillna(\"\").astype(str)\n",
    "    df[\"Question\"] = df[\"Question\"].fillna(\"\").astype(str)\n",
    "    df[\"Answer\"] = df[\"Answer\"].fillna(\"\").astype(str)\n",
    "    df = df[(df[\"Question\"].str.strip() != \"\") & (df[\"Answer\"].str.strip() != \"\")].reset_index(drop=True)\n",
    "    ds = Dataset.from_pandas(df, preserve_index=False)\n",
    "    split = ds.train_test_split(test_size=test_size, seed=seed)\n",
    "    return split[\"train\"], split[\"test\"]\n",
    "\n",
    "def quick_rouge_eval(ds: Dataset, n: int = 20, seed: int = 0, max_new_tokens: int = 180):\n",
    "    rng = random.Random(seed)\n",
    "    idxs = list(range(len(ds)))\n",
    "    rng.shuffle(idxs)\n",
    "    idxs = idxs[:min(n, len(ds))]\n",
    "\n",
    "    scores = []\n",
    "    rows = []\n",
    "    for i in idxs:\n",
    "        ex = ds[i]\n",
    "        qtype = ex.get(\"qtype\", \"\")\n",
    "        q = ex.get(\"Question\", \"\")\n",
    "        ref = ex.get(\"Answer\", \"\")\n",
    "\n",
    "        pred = generate_answer(\n",
    "            model_ft,\n",
    "            q,\n",
    "            qtype=qtype,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=False,   # deterministic for eval\n",
    "        )\n",
    "        s = rouge_l_f1(pred, ref)\n",
    "        scores.append(s)\n",
    "        rows.append((s, qtype, q, pred, ref))\n",
    "\n",
    "    scores_sorted = sorted(rows, key=lambda x: x[0])\n",
    "    mean_score = sum(scores) / max(len(scores), 1)\n",
    "\n",
    "    return mean_score, scores_sorted\n",
    "\n",
    "train_ds, eval_ds = load_split_dataset(DATA_PATH, test_size=0.05, seed=42)\n",
    "\n",
    "N = 15  # keep small on CPU; increase if you want\n",
    "train_mean, train_rows = quick_rouge_eval(train_ds, n=N, seed=1)\n",
    "eval_mean, eval_rows = quick_rouge_eval(eval_ds, n=N, seed=2)\n",
    "\n",
    "print(\"\\n======================\")\n",
    "print(\"Quick Overfitting Check (ROUGE-L F1)\")\n",
    "print(\"======================\")\n",
    "print(f\"Train sample (n={N}) mean ROUGE-L F1: {train_mean:.3f}\")\n",
    "print(f\"Eval  sample (n={N}) mean ROUGE-L F1: {eval_mean:.3f}\")\n",
    "print(\"Rule of thumb: if train >> eval by a big margin, that suggests overfitting.\\n\")\n",
    "\n",
    "print(\"Worst 3 EVAL examples (lowest ROUGE-L):\")\n",
    "for s, qt, q, pred, ref in eval_rows[:3]:\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(f\"ROUGE-L F1: {s:.3f} | qtype: {qt}\")\n",
    "    print(\"Q:\", q)\n",
    "    print(\"PRED:\", textwrap.shorten(pred, width=300, placeholder=\" ...\"))\n",
    "    print(\"REF :\", textwrap.shorten(ref,  width=300, placeholder=\" ...\"))\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 6) OPTIONAL: interactive Q&A loop in Jupyter\n",
    "# ============================================\n",
    "def qa():\n",
    "    print(\"\\nInteractive Q&A (type 'exit' to stop)\\n\")\n",
    "    while True:\n",
    "        q = input(\"You: \").strip()\n",
    "        if q.lower() in {\"exit\", \"quit\"}:\n",
    "            break\n",
    "        a = generate_answer(model_ft, q, qtype=None, max_new_tokens=256, do_sample=True, temperature=0.7, top_p=0.9)\n",
    "        print(\"\\nModel:\", a, \"\\n\")\n",
    "\n",
    "# To start interactive mode, run:\n",
    "# qa()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
